# SPDX-FileCopyrightText: 2023 Carnegie Mellon University - Satyalab
#
# SPDX-License-Identifier: CC0-1.0
# SPDX-License-Identifier: GPL-2.0-only

# The environment variables such as
# ${FACE_THRESHOLD} and ${API_KEY} should
# reside in a .env file along side docker-compose.yaml

services:
  gabriel-server:
    image: xianglic/gabriel-server
    container_name: gabriel-server
    ports:
      - "9099:9099"
      - "5555:5555"
    entrypoint: [ "./main.py", "-t", "30", "-z"]
    restart: unless-stopped
    networks:
      - cnc-net

  telemetry-engine:
    image: xianglic/steeleagle-telemetry-engine:${TAG}
    container_name: telemetry-engine
    restart: unless-stopped
    privileged: true
    entrypoint: [ "./telemetry.py", "-a", "${REDIS_AUTH}"]
    depends_on:
      - gabriel-server
    networks:
      - cnc-net
      - redis
    volumes:
      - ./steeleagle-vol:/images/
    environment:
      - PYTHONPATH=/protocol

  swarm-controller:
    image: xianglic/steeleagle-swarm-controller:${TAG}
    container_name: swarm-controller
    restart: unless-stopped
    ports:
      - "5003:5003"
      - "5004:5004"
      - "6001:6001"
    privileged: true
    entrypoint: [ "./swarm_controller.py", "-a", "${REDIS_AUTH}"]
    volumes:
      - ./steeleagle-vol/compiler/:/compiler
      - ./steeleagle-vol/scripts/:/scripts
      - ./steeleagle-dsl:/dsl
    networks:
      - cnc-net
      - redis
    environment:
      - PYTHONPATH=/protocol

  # test-clients:
  #   image: cmusatyalab/steeleagle:${TAG}
  #   container_name: test-clients
  #   restart: unless-stopped
  #   privileged: true
  #   entrypoint:
  #     [
  #       "../python_client/drone_client.py",
  #       "--s",
  #       "gabriel-server"
  #     ]
  #   depends_on:
  #     - command-engine
  #   networks:
  #     - cnc-net

  http-server:
    image: httpd:2.4
    container_name: http-server
    ports:
      - "${HTTP_PORT}:80"
    restart: unless-stopped
    logging:
      driver: none
    networks:
      - cnc-net
    volumes:
      - ./steeleagle-vol:/usr/local/apache2/htdocs

  #       #openscout-face-engine:
  #       #  image: cmusatyalab/openscout:${OPENSCOUT_TAG}
  #       #  container_name: openscout-face-engine
  #       #  restart: unless-stopped
  #       #  privileged: true
  #       #  entrypoint:
  #       #    [
  #       #      "./face.py",
  #       #      "--source",
  #       #      "telemetry",
  #       #      "--endpoint",
  #       #      "http://openface-service:5000",
  #       #      "--threshold",
  #       #      "${FACE_THRESHOLD}",
  #       #      "${STORE}"
  #       #    ]
  #       #  #to use MS Face Cognitive Service, make this the entrypoint instead and use the ms-face-server container...
  #       #  #entrypoint: ["./face.py", "--msface", "--endpoint", "http://ms-face-service:5000","--apikey", "${API_KEY}", "--threshold", "${FACE_THRESHOLD}"]
  #       #  volumes:
  #       #    - ./steeleagle-vol:/openscout/server/images/
  #       #    - training-vol:/openscout/server/training/
  #       #  depends_on:
  #       #    - gabriel-server
  #       #    - openface-service
  #       #    #- ms-face-service
  #       #  networks:
  #       #    - cnc-net
  #       #    - redis
  #       #  environment:
  #       #    - WEBSERVER=${WEBSERVER_URL}:${HTTP_PORT}

  # obstacle-engine:
  #   image: cmusatyalab/steeleagle-vision-engines:${TAG}
  #   container_name: obstacle-engine
  #   restart: unless-stopped
  #   privileged: true
  #   entrypoint: ["./depth.py", "--source", "telemetry", "--model", "${DEPTH_MODEL}", "--threshold", "${DEPTH_THRESHOLD}", "${STORE}", "-a", "${REDIS_AUTH}", "${USE_METRIC3D}"]
  #   # for NVIDIA GPUs
  #   #gpus: all     # not yet supported by docker-compose
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             capabilities:
  #               - gpu
  #   volumes:
  #     - ./steeleagle-vol:/steeleagle/images/
  #     - ./models:/root/.cache/torch/hub/
  #   depends_on:
  #     - gabriel-server
  #   networks:
  #     - cnc-net
  #     - redis
  #   environment:
  #     - PYTHONPATH=/steeleagle/protocol
  #   #environment:
  #   #  - TF_FORCE_GPU_ALLOW_GROWTH=true #the following environment variable may be necessary if your GPU only has a modest (~2GB) amount of RAM
  #   #  - CUDA_VISIBLE_DEVICES=1 #set this if you want to force CPU only

  # object-engine:
  #   image: cmusatyalab/steeleagle-vision-engines:${TAG}
  #   container_name: object-engine
  #   restart: unless-stopped
  #   privileged: true
  #   entrypoint:
  #     [
  #       "./obj.py",
  #       "--source",
  #       "telemetry",
  #       "--model",
  #       "${DNN}",
  #       "--threshold",
  #       "${OBJ_THRESHOLD}",
  #       "--exclude",
  #       "${EXCLUSIONS}",
  #       "${STORE}",
  #       "-a",
  #       "${REDIS_AUTH}",
  #       "-hsv",
  #       "${HSV_THRESHOLD}",
  #       "--geofence",
  #       "geofence.kml",
  #       "--ttl",
  #       "30"
  #     ]
  #   # for NVIDIA GPUs
  #   # gpus: all     # not yet supported by docker-compose
  #   runtime: nvidia
  #   volumes:
  #     - ./models:/steeleagle/model/
  #     - ./steeleagle-vol:/steeleagle/images/
  #     - ./geofence:/steeleagle/geofence/
  #   depends_on:
  #     - gabriel-server
  #   networks:
  #     - cnc-net
  #     - redis
  #   environment:
  #     - WEBSERVER=${WEBSERVER_URL}:${HTTP_PORT}
  #     - PYTHONPATH=/steeleagle/protocol
  #   #  - TF_FORCE_GPU_ALLOW_GROWTH=true #the following environment variable may be necessary if your GPU only has a modest (~2GB) amount of RAM
  #   #  - CUDA_VISIBLE_DEVICES=-1 #set this if you want to force CPU only

  # slam-engine:
  #   # image: xujingao/steeleagle-slam-engine
  #   image: cmusatyalab/steeleagle-slam-engine
  #   container_name: slam-engine
  #   restart: unless-stopped
  #   privileged: true
  #   # entrypoint: ["python3","./slam.py", "-s", "128.2.208.19", "-t", "transform.json", "-a", "${REDIS_AUTH}", "-g", "tcp://gabriel-server:5555", "-src", "telemetry"]
  #   entrypoint: ["python3","./slam.py", "-s", "lambda2.elijah.cs.cmu.edu", "-a", "${REDIS_AUTH}",  "--source", "telemetry"]
  #   depends_on:
  #     - gabriel-server
  #     - redis
  #   networks:
  #     - cnc-net
  #     - redis
  #   environment:
  #     - PYTHONPATH=/steeleagle/protocol
  #   volumes:
  #     - ./steeleagle-vol:/steeleagle/images/

  # OpenFace is the default for face recognition
  #openface-service:
  #  image: cmusatyalab/openface
  #  container_name: openface-service
  #  ports:
  #    - "5000:5000"
  #  restart: unless-stopped
  #  privileged: true
  #  entrypoint:
  #    [
  #      "python",
  #      "/root/openface-rest.py",
  #      "/openscout/server/training/"
  #    ]
  #  volumes:
  #    - training-vol:/openscout/server/training/
  #  networks:
  #    - cnc-net

  # or the MS Face Cognitive Server can be used (Azure Account Required)
  # ms-face-service:
  #   image: containerpreview.azurecr.io/microsoft/cognitive-services-face
  #   container_name: ms-face-service
  #   restart: unless-stopped
  #   ports:
  #     - "5000:5000"
  #   networks:
  #     - cnc-net
  #   cpus: '1.0'
  #   mem_reservation: 4gb
  #   environment:
  #     - Eula=accept
  #     - Billing=${BILLING_ENDPOINT}
  #     - ApiKey=${API_KEY}
  go2rtc:
    image: alexxit/go2rtc
    network_mode: host       # important for WebRTC, HomeKit, UDP cameras
    privileged: true         # only for FFmpeg hardware transcoding
    restart: unless-stopped  # autorestart on fail or config change from WebUI
    environment:
      - TZ=Atlantic/Bermuda  # timezone in logs
    volumes:
      - "~/go2rtc:/config"   # folder for go2rtc.yaml file (edit from WebUI)
      - ./steeleagle-vol:/tmp
  redis:
    image: redis/redis-stack:${REDIS_VERSION}
    container_name: redis
    restart: unless-stopped
    privileged: true
    ports:
      - 6379:6379
      - ${REDIS_HOST}:8001:8001
    networks:
      - redis
    volumes:
      - ./redis:/data
      - ./redis/redis.conf:/redis-stack.conf

networks:
  cnc-net:
    name: cnc-net
    ipam:
      driver: default
      config:
        - subnet: 11.11.0.0/24
  redis:
    ipam:
      driver: default
      config:
        - subnet: 12.12.0.0/24
volumes:
  training-vol:
